{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "jwILyLqxAXMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics --upgrade"
      ],
      "metadata": {
        "id": "fMc_mAnnGnlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîß Environment Setup & CUDA Verification\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import subprocess\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ Checking system Python and CUDA installation...\")\n",
        "\n",
        "# Check PyTorch installation (should be system-wide CUDA version)\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "\n",
        "    # Test CUDA availability\n",
        "    cuda_available = torch.cuda.is_available()\n",
        "    print(f\"üî• CUDA available: {cuda_available}\")\n",
        "\n",
        "    if cuda_available:\n",
        "        print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"üéØ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        print(f\"üéØ CUDA Version: {torch.version.cuda}\")\n",
        "        pytorch_working = True\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è CUDA not available, will use CPU\")\n",
        "        pytorch_working = True  # Still working, just on CPU\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå PyTorch not found: {e}\")\n",
        "    print(\"Please ensure PyTorch is installed with: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\")\n",
        "    pytorch_working = False\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå PyTorch error: {e}\")\n",
        "    pytorch_working = False\n",
        "\n",
        "if pytorch_working:\n",
        "    print(\"\\nüì¶ Importing required libraries...\")\n",
        "\n",
        "    # Import other required libraries\n",
        "    import yaml\n",
        "    import shutil\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from pathlib import Path\n",
        "    import cv2\n",
        "    from PIL import Image\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import glob\n",
        "    from collections import Counter\n",
        "    import json\n",
        "\n",
        "    # Set up device and optimization\n",
        "    if torch.cuda.is_available():\n",
        "        # GPU optimization\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        DEVICE = 'cuda'\n",
        "        USE_GPU = True\n",
        "        print(f\"üöÄ Using GPU acceleration on {torch.cuda.get_device_name(0)}!\")\n",
        "    else:\n",
        "        DEVICE = 'cpu'\n",
        "        USE_GPU = False\n",
        "        print(\"‚ö†Ô∏è Using CPU (CUDA not available)\")\n",
        "\n",
        "    # Import YOLOv8 (assuming it's already installed as per the previous cell)\n",
        "    try:\n",
        "        from ultralytics import YOLO\n",
        "        print(\"‚úÖ YOLOv8 imported successfully\")\n",
        "    except ImportError:\n",
        "         print(\"‚ùå YOLOv8 not found. Please ensure it's installed with: pip install ultralytics\")\n",
        "\n",
        "\n",
        "    # Set random seeds for reproducibility\n",
        "    random.seed(42)\n",
        "    np.random.seed(42)\n",
        "    torch.manual_seed(42)\n",
        "    if USE_GPU:\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "\n",
        "    print(f\"\\nüöÄ Environment ready!\")\n",
        "    print(f\"   Device: {DEVICE}\")\n",
        "    print(f\"   Working Directory: {os.getcwd()}\")\n",
        "    print(f\"   Python: {sys.executable}\")\n",
        "\n",
        "    # List available folders\n",
        "    available_folders = [d.name for d in Path('.').iterdir() if d.is_dir()]\n",
        "    print(f\"   Available folders: {available_folders}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Environment setup failed. Please ensure PyTorch with CUDA is installed.\")"
      ],
      "metadata": {
        "id": "fSecT8B2g7C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÇ Dataset Configuration & Path Setup\n",
        "# Model Configuration - Using YOLOv8x for maximum accuracy\n",
        "SELECTED_MODEL = 'yolov8x'  # Best accuracy accuracy\n",
        "EPOCHS = 300  # More epochs for better accuracy\n",
        "BATCH_SIZE = 8 if USE_GPU else 4  # Adjusted for YOLOv8x memory requirements\n",
        "IMG_SIZE = 1024  # Larger image size for better QR detection\n",
        "PATIENCE = 50\n",
        "CONFIDENCE_THRESHOLD = 0.1  # Lower threshold for better recall\n",
        "IOU_THRESHOLD = 0.5\n",
        "LEARNING_RATE = 0.0005  # Lower LR for better convergence\n",
        "\n",
        "# Dataset Paths - Exact structure you mentioned\n",
        "DATASET_ROOT = Path(\"/content/drive/MyDrive/QR_Dataset/QR_Dataset\")\n",
        "TRAIN_IMAGES = DATASET_ROOT / \"/Users/Kareem/Documents/1Pharmacy/QR_Dataset/train_images\"\n",
        "TRAIN_LABELS = Path(\"/Users/Kareem/Documents/1Pharmacy/QR_Dataset/train_label\")  # Updated path\n",
        "TEST_IMAGES = DATASET_ROOT / \"/Users/Kareem/Documents/1Pharmacy/QR_Dataset/test_images\"\n",
        "TEST_LABELS = Path(\"/Users/Kareem/Documents/1Pharmacy/QR_Dataset/test_label\")    # Updated path\n",
        "\n",
        "print(f\"üéØ Configuration:\")\n",
        "print(f\"   Model: {SELECTED_MODEL} (Maximum Accuracy)\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Image Size: {IMG_SIZE}\")\n",
        "print(f\"   Device: {DEVICE}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset Structure:\")\n",
        "print(f\"   Train Images: {TRAIN_IMAGES}\")\n",
        "print(f\"   Train Labels: {TRAIN_LABELS}\")\n",
        "print(f\"   Test Images: {TEST_IMAGES}\")\n",
        "print(f\"   Test Labels: {TEST_LABELS}\")\n",
        "\n",
        "# Verify dataset exists\n",
        "for path in [TRAIN_IMAGES, TRAIN_LABELS, TEST_IMAGES, TEST_LABELS]:\n",
        "    if path.exists():\n",
        "        print(f\"   ‚úÖ {path.name}: Found\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {path.name}: Not found\")\n",
        "        # Removed mkdir since the user expects the data to be in the drive\n",
        "        # path.mkdir(parents=True, exist_ok=True)\n",
        "        # print(f\"   üìÅ Created {path}\")\n",
        "\n",
        "\n",
        "# Count files\n",
        "train_imgs = list(TRAIN_IMAGES.glob('*.jpg')) + list(TRAIN_IMAGES.glob('*.png'))\n",
        "train_labels = [f for f in TRAIN_LABELS.glob('*.txt') if f.name != 'classes.txt']\n",
        "test_imgs = list(TEST_IMAGES.glob('*.jpg')) + list(TEST_IMAGES.glob('*.png'))\n",
        "test_labels = [f for f in TEST_LABELS.glob('*.txt') if f.name != 'classes.txt']\n",
        "\n",
        "\n",
        "print(f\"\\nüìä Dataset Summary:\")\n",
        "print(f\"   Training Images: {len(train_imgs)}\")\n",
        "print(f\"   Training Labels: {len(train_labels)}\")\n",
        "print(f\"   Test Images: {len(test_imgs)}\")\n",
        "print(f\"   Test Labels: {len(test_labels)}\")\n",
        "\n",
        "if len(train_imgs) == 0:\n",
        "    print(\"‚ö†Ô∏è No training images found! Please add images to train_images folder.\")\n",
        "if len(train_labels) == 0:\n",
        "    print(\"‚ö†Ô∏è No training labels found! Please add LabelImg annotations to train_label folder.\")"
      ],
      "metadata": {
        "id": "Gd3-_hLShgda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd3-_LShgda"
      },
      "source": [
        "# üìÇ Dataset Configuration & Path Setup\n",
        "# Model Configuration - Using YOLOv8x for maximum accuracy\n",
        "SELECTED_MODEL = 'yolov8x'  # Best accuracy accuracy\n",
        "EPOCHS = 300  # More epochs for better accuracy\n",
        "BATCH_SIZE = 8 if USE_GPU else 4  # Adjusted for YOLOv8x memory requirements\n",
        "IMG_SIZE = 1024  # Larger image size for better QR detection\n",
        "PATIENCE = 50\n",
        "CONFIDENCE_THRESHOLD = 0.1  # Lower threshold for better recall\n",
        "IOU_THRESHOLD = 0.5\n",
        "LEARNING_RATE = 0.0005  # Lower LR for better convergence\n",
        "\n",
        "# Dataset Paths - Adjusted for Google Drive\n",
        "# Assumes your dataset is in /content/drive/MyDrive/QR_Dataset/QR_Dataset\n",
        "DATASET_ROOT = Path(\"/Users/Kareem/Documents/1Pharmacy/QR_Dataset\")\n",
        "TRAIN_IMAGES = DATASET_ROOT / \"train_images\"\n",
        "TRAIN_LABELS = DATASET_ROOT / \"train_label\"  # Assuming labels are in an annotation folder at dataset root\n",
        "TEST_IMAGES = DATASET_ROOT / \"test_images\"\n",
        "TEST_LABELS = DATASET_ROOT / \"test_label\"    # Assuming labels are in an annotation folder at dataset root\n",
        "\n",
        "print(f\"üéØ Configuration:\")\n",
        "print(f\"   Model: {SELECTED_MODEL} (Maximum Accuracy)\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"   Image Size: {IMG_SIZE}\")\n",
        "print(f\"   Device: {DEVICE}\")\n",
        "print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset Structure:\")\n",
        "print(f\"   Train Images: {TRAIN_IMAGES}\")\n",
        "print(f\"   Train Labels: {TRAIN_LABELS}\")\n",
        "print(f\"   Test Images: {TEST_IMAGES}\")\n",
        "print(f\"   Test Labels: {TEST_LABELS}\")\n",
        "\n",
        "# Verify dataset exists\n",
        "for path in [TRAIN_IMAGES, TRAIN_LABELS, TEST_IMAGES, TEST_LABELS]:\n",
        "    if path.exists():\n",
        "        print(f\"   ‚úÖ {path.name}: Found\")\n",
        "    else:\n",
        "        print(f\"   ‚ùå {path.name}: Not found\")\n",
        "        # Removed mkdir since the user expects the data to be in the drive\n",
        "        # path.mkdir(parents=True, exist_ok=True)\n",
        "        # print(f\"   üìÅ Created {path}\")\n",
        "\n",
        "\n",
        "# Count files\n",
        "train_imgs = list(TRAIN_IMAGES.glob('*.jpg')) + list(TRAIN_IMAGES.glob('*.png')) + list(TRAIN_IMAGES.glob('*.jpeg'))\n",
        "train_labels = [f for f in TRAIN_LABELS.glob('*.txt') if f.name != 'classes.txt']\n",
        "test_imgs = list(TEST_IMAGES.glob('*.jpg')) + list(TEST_IMAGES.glob('*.png')) + list(TEST_IMAGES.glob('*.jpeg'))\n",
        "test_labels = [f for f in TEST_LABELS.glob('*.txt') if f.name != 'classes.txt']\n",
        "\n",
        "\n",
        "print(f\"\\nüìä Dataset Summary:\")\n",
        "print(f\"   Training Images: {len(train_imgs)}\")\n",
        "print(f\"   Training Labels: {len(train_labels)}\")\n",
        "print(f\"   Test Images: {len(test_imgs)}\")\n",
        "print(f\"   Test Labels: {len(test_labels)}\")\n",
        "\n",
        "if len(train_imgs) == 0:\n",
        "    print(\"‚ö†Ô∏è No training images found! Please add images to train_images folder.\")\n",
        "if len(train_labels) == 0:\n",
        "    print(\"‚ö†Ô∏è No training labels found! Please add LabelImg annotations to train_label folder.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîß Label Processing & Class Normalization\n",
        "def process_and_normalize_labels():\n",
        "    \"\"\"\n",
        "    Process all label files and convert all classes to single QR class (0)\n",
        "    Handles multiple QR codes per image and fixes annotation issues\n",
        "    \"\"\"\n",
        "    print(\"üîß Processing and normalizing labels...\")\n",
        "\n",
        "    # Do not create classes.txt here. This should be in the dataset root\n",
        "    # or defined in the data.yaml file for training.\n",
        "    # classes_file = TRAIN_LABELS / \"classes.txt\"\n",
        "    # with open(classes_file, 'w') as f:\n",
        "    #     f.write('QR_Code\\n')\n",
        "\n",
        "    # Also create for test labels\n",
        "    # test_classes_file = TEST_LABELS / \"classes.txt\"\n",
        "    # with open(test_classes_file, 'w') as f:\n",
        "    #     f.write('QR_Code\\n')\n",
        "\n",
        "    print(\"‚ÑπÔ∏è Class definition will be handled in the data.yaml file.\")\n",
        "\n",
        "    # Process training labels\n",
        "    processed_count = 0\n",
        "    fixed_count = 0\n",
        "    total_objects = 0\n",
        "\n",
        "    for label_file in TRAIN_LABELS.glob(\"*.txt\"):\n",
        "        if label_file.name == \"classes.txt\":\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(label_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # Check if the file is empty\n",
        "            if not lines:\n",
        "                print(f\"‚ö†Ô∏è Skipping empty label file: {label_file.name}\")\n",
        "                continue\n",
        "\n",
        "            processed_lines = []\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 5:\n",
        "                    # Convert any class ID to 0 (QR_Code)\n",
        "                    original_class = int(parts[0])\n",
        "                    if original_class != 0:\n",
        "                        fixed_count += 1\n",
        "\n",
        "                    # Normalize coordinates (ensure they're within 0-1 range)\n",
        "                    x_center = max(0.0, min(1.0, float(parts[1])))\n",
        "                    y_center = max(0.0, min(1.0, float(parts[2])))\n",
        "                    width = max(0.001, min(1.0, float(parts[3])))  # Minimum width to avoid zero-size boxes\n",
        "                    height = max(0.001, min(1.0, float(parts[4])))  # Minimum height to avoid zero-size boxes\n",
        "\n",
        "                    # Convert to class 0 (QR_Code)\n",
        "                    processed_line = f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "                    processed_lines.append(processed_line)\n",
        "                    total_objects += 1\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Skipping malformed line in {label_file.name}: {line}\")\n",
        "\n",
        "\n",
        "            # Write back processed labels\n",
        "            if processed_lines:\n",
        "                with open(label_file, 'w') as f:\n",
        "                    f.write('\\n'.join(processed_lines) + '\\n')\n",
        "                processed_count += 1\n",
        "            # If processed_lines is empty after filtering, the file might have contained only malformed lines\n",
        "            elif lines:\n",
        "                 print(f\"‚ö†Ô∏è No valid labels found after processing {label_file.name}. File might contain only malformed lines.\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error processing {label_file.name}: {e}\")\n",
        "\n",
        "    # Process test labels similarly\n",
        "    test_processed = 0\n",
        "    for label_file in TEST_LABELS.glob(\"*.txt\"):\n",
        "        if label_file.name == \"classes.txt\":\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            with open(label_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # Check if the file is empty\n",
        "            if not lines:\n",
        "                print(f\"‚ö†Ô∏è Skipping empty test label file: {label_file.name}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "            processed_lines = []\n",
        "            for line in lines:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 5:\n",
        "                    # Convert to class 0 and normalize\n",
        "                    x_center = max(0.0, min(1.0, float(parts[1])))\n",
        "                    y_center = max(0.0, min(1.0, float(parts[2])))\n",
        "                    width = max(0.001, min(1.0, float(parts[3])))\n",
        "                    height = max(0.001, min(1.0, float(parts[4])))\n",
        "\n",
        "                    processed_line = f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "                    processed_lines.append(processed_line)\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Skipping malformed line in test {label_file.name}: {line}\")\n",
        "\n",
        "\n",
        "            if processed_lines:\n",
        "                with open(label_file, 'w') as f:\n",
        "                    f.write('\\n'.join(processed_lines) + '\\n')\n",
        "                test_processed += 1\n",
        "            # If processed_lines is empty after filtering, the file might have contained only malformed lines\n",
        "            elif lines:\n",
        "                 print(f\"‚ö†Ô∏è No valid test labels found after processing {label_file.name}. File might contain only malformed lines.\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error processing test {label_file.name}: {e}\")\n",
        "\n",
        "    print(f\"üìä Label Processing Results:\")\n",
        "    print(f\"   Training labels processed: {processed_count}\")\n",
        "    print(f\"   Test labels processed: {test_processed}\")\n",
        "    print(f\"   Total QR objects: {total_objects}\")\n",
        "    print(f\"   Class IDs fixed: {fixed_count}\")\n",
        "    print(f\"‚úÖ All labels normalized to single QR class (0)\")\n",
        "\n",
        "    return total_objects\n",
        "\n",
        "# Run label processing\n",
        "total_qr_objects = process_and_normalize_labels()"
      ],
      "metadata": {
        "id": "oxR26s4bkcJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìä Dataset Analysis & Validation\n",
        "def analyze_dataset():\n",
        "    \"\"\"Comprehensive dataset analysis\"\"\"\n",
        "    print(\"üîç Analyzing dataset...\")\n",
        "\n",
        "    # Analyze training data\n",
        "    train_images = list(TRAIN_IMAGES.glob('*.jpg')) + list(TRAIN_IMAGES.glob('*.png'))\n",
        "    train_labels = [f for f in TRAIN_LABELS.glob('*.txt') if f.name != 'classes.txt']\n",
        "\n",
        "    # Check image-label pairs\n",
        "    matched_pairs = 0\n",
        "    missing_labels = []\n",
        "    missing_images = []\n",
        "\n",
        "    for img_file in train_images:\n",
        "        label_file = TRAIN_LABELS / f\"{img_file.stem}.txt\"\n",
        "        if label_file.exists():\n",
        "            matched_pairs += 1\n",
        "        else:\n",
        "            missing_labels.append(img_file.name)\n",
        "\n",
        "    for label_file in train_labels:\n",
        "        img_jpg = TRAIN_IMAGES / f\"{label_file.stem}.jpg\"\n",
        "        img_png = TRAIN_IMAGES / f\"{label_file.stem}.png\"\n",
        "        if not (img_jpg.exists() or img_png.exists()):\n",
        "            missing_images.append(label_file.name)\n",
        "\n",
        "    # Analyze QR code statistics\n",
        "    qr_counts = []\n",
        "    bbox_areas = []\n",
        "\n",
        "    for label_file in train_labels:\n",
        "        try:\n",
        "            with open(label_file, 'r') as f:\n",
        "                lines = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "            qr_count = len(lines)\n",
        "            qr_counts.append(qr_count)\n",
        "\n",
        "            for line in lines:\n",
        "                parts = line.split()\n",
        "                if len(parts) >= 5:\n",
        "                    width = float(parts[3])\n",
        "                    height = float(parts[4])\n",
        "                    area = width * height\n",
        "                    bbox_areas.append(area)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    print(f\"üìä Dataset Analysis Results:\")\n",
        "    print(f\"   Total training images: {len(train_images)}\")\n",
        "    print(f\"   Total training labels: {len(train_labels)}\")\n",
        "    print(f\"   Matched image-label pairs: {matched_pairs}\")\n",
        "    print(f\"   Missing labels: {len(missing_labels)}\")\n",
        "    print(f\"   Missing images: {len(missing_images)}\")\n",
        "\n",
        "    if qr_counts:\n",
        "        print(f\"\\nüéØ QR Code Statistics:\")\n",
        "        print(f\"   Total QR codes: {sum(qr_counts)}\")\n",
        "        print(f\"   Images with QR codes: {len(qr_counts)}\")\n",
        "        print(f\"   Avg QR codes per image: {np.mean(qr_counts):.2f}\")\n",
        "        print(f\"   Max QR codes in single image: {max(qr_counts)}\")\n",
        "        print(f\"   Min QR codes in single image: {min(qr_counts)}\")\n",
        "\n",
        "    if bbox_areas:\n",
        "        print(f\"\\nüìê Bounding Box Analysis:\")\n",
        "        print(f\"   Avg area: {np.mean(bbox_areas):.4f}\")\n",
        "        print(f\"   Min area: {np.min(bbox_areas):.4f}\")\n",
        "        print(f\"   Max area: {np.max(bbox_areas):.4f}\")\n",
        "        print(f\"   Median area: {np.median(bbox_areas):.4f}\")\n",
        "\n",
        "    # Print warnings\n",
        "    if missing_labels:\n",
        "        print(f\"‚ö†Ô∏è Images without labels: {missing_labels[:5]}{'...' if len(missing_labels) > 5 else ''}\")\n",
        "    if missing_images:\n",
        "        print(f\"‚ö†Ô∏è Labels without images: {missing_images[:5]}{'...' if len(missing_images) > 5 else ''}\")\n",
        "\n",
        "    return {\n",
        "        'total_images': len(train_images),\n",
        "        'total_labels': len(train_labels),\n",
        "        'matched_pairs': matched_pairs,\n",
        "        'total_qr_codes': sum(qr_counts) if qr_counts else 0,\n",
        "        'avg_qr_per_image': np.mean(qr_counts) if qr_counts else 0\n",
        "    }\n",
        "\n",
        "# Run dataset analysis\n",
        "dataset_stats = analyze_dataset()"
      ],
      "metadata": {
        "id": "D8Ey65Y6kvdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìÅ YOLO Dataset Preparation\n",
        "def prepare_yolo_dataset():\n",
        "    \"\"\"Prepare dataset in YOLO format with train/val split\"\"\"\n",
        "    print(\"üìÅ Preparing YOLO dataset structure...\")\n",
        "\n",
        "    # Create dataset directory structure\n",
        "    dataset_dir = Path(\"./yolo_qr_dataset\")\n",
        "\n",
        "    # Remove existing dataset to start fresh\n",
        "    if dataset_dir.exists():\n",
        "        shutil.rmtree(dataset_dir)\n",
        "\n",
        "    # Create directory structure\n",
        "    for split in ['train', 'val']:\n",
        "        for folder in ['images', 'labels']:\n",
        "            (dataset_dir / split / folder).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Get all image files with corresponding labels\n",
        "    train_images = []\n",
        "    for img_ext in ['*.jpg', '*.png', '*.jpeg']:\n",
        "        train_images.extend(list(TRAIN_IMAGES.glob(img_ext)))\n",
        "\n",
        "    # Filter images that have corresponding labels\n",
        "    valid_images = []\n",
        "    for img_file in train_images:\n",
        "        label_file = TRAIN_LABELS / f\"{img_file.stem}.txt\"\n",
        "        if label_file.exists():\n",
        "            valid_images.append(img_file)\n",
        "\n",
        "    print(f\"   Total images: {len(train_images)}\")\n",
        "    print(f\"   Images with labels: {len(valid_images)}\")\n",
        "\n",
        "    if len(valid_images) == 0:\n",
        "        raise ValueError(\"No valid image-label pairs found!\")\n",
        "\n",
        "    # Split dataset (80% train, 20% validation)\n",
        "    train_files, val_files = train_test_split(\n",
        "        valid_images,\n",
        "        train_size=0.8,\n",
        "        random_state=42,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    print(f\"   Training split: {len(train_files)} images\")\n",
        "    print(f\"   Validation split: {len(val_files)} images\")\n",
        "\n",
        "    # Copy files to respective directories\n",
        "    def copy_files(file_list, split_name):\n",
        "        for img_file in file_list:\n",
        "            # Copy image\n",
        "            dst_img = dataset_dir / split_name / \"images\" / img_file.name\n",
        "            shutil.copy2(img_file, dst_img)\n",
        "\n",
        "            # Copy corresponding label\n",
        "            label_file = TRAIN_LABELS / f\"{img_file.stem}.txt\"\n",
        "            dst_label = dataset_dir / split_name / \"labels\" / f\"{img_file.stem}.txt\"\n",
        "            shutil.copy2(label_file, dst_label)\n",
        "\n",
        "    copy_files(train_files, \"train\")\n",
        "    copy_files(val_files, \"val\")\n",
        "\n",
        "    # Create data.yaml configuration file\n",
        "    data_yaml = {\n",
        "        'path': str(dataset_dir.absolute()),\n",
        "        'train': 'train/images',\n",
        "        'val': 'val/images',\n",
        "        'nc': 1,  # Number of classes (single QR class)\n",
        "        'names': {0: 'QR_Code'}  # Class names\n",
        "    }\n",
        "\n",
        "    yaml_path = dataset_dir / \"data.yaml\"\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "    print(f\"‚úÖ YOLO dataset prepared!\")\n",
        "    print(f\"   Dataset path: {dataset_dir}\")\n",
        "    print(f\"   Configuration: {yaml_path}\")\n",
        "\n",
        "    return dataset_dir\n",
        "\n",
        "# Prepare the dataset\n",
        "dataset_dir = prepare_yolo_dataset()"
      ],
      "metadata": {
        "id": "1BGl2xt3lo1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üéØ Maximum Accuracy YOLOv8x Training\n",
        "def train_maximum_accuracy_model():\n",
        "    \"\"\"Train YOLOv8x with hyperparameters optimized for maximum QR detection accuracy\"\"\"\n",
        "\n",
        "    # Load the most powerful YOLO model - Using the local path provided by the user\n",
        "    # Reduced model size to yolov8s for better performance on 4GB GPU\n",
        "    SELECTED_MODEL = 'yolov8s'\n",
        "    print(f\"üöÄ Starting {SELECTED_MODEL} training for maximum QR detection accuracy...\")\n",
        "\n",
        "    # Use the user-provided local model path\n",
        "    model_path = Path(\"/Users/Kareem/Documents/1Pharmacy/yolov8s.pt\")\n",
        "\n",
        "    if not model_path.exists():\n",
        "        print(f\"‚ùå Model weights not found at the specified path: {model_path}\")\n",
        "        print(\"Please ensure the file exists at this location.\")\n",
        "        return None, None # Exit if the model is not found\n",
        "\n",
        "    print(f\"Attempting to load model from: {model_path}\")\n",
        "    model = YOLO(str(model_path)) # Convert Path object to string\n",
        "    print(f\"‚úÖ Loaded {SELECTED_MODEL} pre-trained model\")\n",
        "\n",
        "\n",
        "    # Clear GPU memory\n",
        "    if USE_GPU:\n",
        "        torch.cuda.empty_cache()\n",
        "        print(f\"üßπ Cleared GPU memory\")\n",
        "\n",
        "    # Training arguments optimized for maximum accuracy\n",
        "    training_args = {\n",
        "        # Dataset configuration\n",
        "        'data': str(dataset_dir / 'data.yaml'), # Ensure this path is correct for local runtime if data is also local\n",
        "        'epochs': EPOCHS,  # Increased epochs back to original for accuracy\n",
        "        'batch': 1 if USE_GPU else 4, # Further reduced batch size to mitigate CUDA out of memory\n",
        "        'imgsz': 640,  # Reduced image size\n",
        "        'device': DEVICE,\n",
        "        'workers': 0, # Reduced workers to 0 to avoid multiprocessing issues on Windows\n",
        "\n",
        "        # Model settings\n",
        "        # 'model': SELECTED_MODEL, # No longer needed as we load from path\n",
        "        'patience': PATIENCE,\n",
        "        'save_period': 20,  # Save checkpoint every 20 epochs\n",
        "        'project': 'qr_detection_max_accuracy',\n",
        "        'name': f'qr_{SELECTED_MODEL}_best_accuracy',\n",
        "        'exist_ok': True,\n",
        "        'verbose': True,\n",
        "        'seed': 42,\n",
        "        'deterministic': True,\n",
        "        'single_cls': True,  # Single class optimization\n",
        "\n",
        "        # Optimizer settings for maximum accuracy\n",
        "        'optimizer': 'AdamW',  # Better convergence than SGD\n",
        "        'lr0': LEARNING_RATE,  # Lower learning rate for stability\n",
        "        'lrf': 0.001,  # Very low final learning rate\n",
        "        'momentum': 0.9,\n",
        "        'weight_decay': 0.001,  # Stronger regularization\n",
        "        'warmup_epochs': 5.0,  # More warmup epochs\n",
        "        'warmup_momentum': 0.8,\n",
        "        'warmup_bias_lr': 0.1,\n",
        "\n",
        "        # Data augmentation optimized for QR codes (minimal to preserve structure)\n",
        "        'hsv_h': 0.005,    # Very minimal hue changes\n",
        "        'hsv_s': 0.2,      # Moderate saturation changes\n",
        "        'hsv_v': 0.2,      # Moderate brightness changes\n",
        "        'degrees': 5.0,    # Very small rotations only\n",
        "        'translate': 0.05, # Minimal translation\n",
        "        'scale': 0.1,      # Minimal scaling\n",
        "        'shear': 1.0,      # Minimal shear\n",
        "        'perspective': 0.0, # No perspective transform\n",
        "        'flipud': 0.0,     # No vertical flipping\n",
        "        'fliplr': 0.0,     # No horizontal flipping\n",
        "        'mosaic': 0.3,     # Reduced mosaic for better QR preservation\n",
        "        'mixup': 0.0,      # No mixup to preserve QR structure\n",
        "        'copy_paste': 0.0, # No copy-paste\n",
        "        'auto_augment': None, # Disable auto augmentation\n",
        "        'erasing': 0.0,    # No random erasing\n",
        "\n",
        "        # Loss function weights (optimized for detection accuracy)\n",
        "        'box': 10.0,       # Higher weight for box regression\n",
        "        'cls': 1.0,        # Standard classification weight\n",
        "        'dfl': 2.0,        # Higher DFL weight for precise localization\n",
        "        'pose': 12.0,      # Pose weight (if applicable)\n",
        "        'kobj': 1.0,       # Keypoint objectness\n",
        "        'label_smoothing': 0.0,  # No label smoothing for precise QR detection\n",
        "\n",
        "        # Validation and evaluation\n",
        "        'val': True,\n",
        "        'split': 'val',\n",
        "        'save_json': True,\n",
        "        'save_hybrid': True,\n",
        "        'conf': CONFIDENCE_THRESHOLD,\n",
        "        'iou': IOU_THRESHOLD,\n",
        "        'max_det': 100,    # Allow more detections per image for multiple QRs\n",
        "        'half': USE_GPU,     # Use FP16 for mixed precision if GPU is available\n",
        "        'dnn': False,\n",
        "        'plots': True,\n",
        "        'save': True,\n",
        "        'save_txt': True,\n",
        "        'save_conf': True,\n",
        "        'save_crop': False,\n",
        "        'show_labels': True,\n",
        "        'show_conf': True,\n",
        "        'show_boxes': True,\n",
        "\n",
        "        # Advanced settings for accuracy\n",
        "        'amp': False,      # Disable mixed precision to prevent unwanted downloads\n",
        "        'fraction': 1.0,   # Use 100% of dataset\n",
        "        'profile': False,\n",
        "        'freeze': None,    # Don't freeze any layers\n",
        "        'multi_scale': True,  # Enable multi-scale training\n",
        "        'overlap_mask': True,\n",
        "        'mask_ratio': 4,\n",
        "        'dropout': 0.1,    # Slight dropout for regularization\n",
        "        # 'val_period': 5,   # Validate every 5 epochs - REMOVED, NOT A VALID ARGUMENT\n",
        "    }\n",
        "\n",
        "    print(f\"üéØ Training Configuration:\")\n",
        "    print(f\"   Model: {SELECTED_MODEL}\")\n",
        "    print(f\"   Epochs: {EPOCHS}\")\n",
        "    print(f\"   Batch Size: {training_args['batch']}\") # Print the actual batch size being used\n",
        "    print(f\"   Image Size: {IMG_SIZE}\")\n",
        "    print(f\"   Learning Rate: {LEARNING_RATE}\")\n",
        "    print(f\"   Device: {DEVICE}\")\n",
        "    print(f\"   Mixed Precision: {'Enabled' if USE_GPU else 'Disabled'} (based on GPU availability)\")\n",
        "\n",
        "    try:\n",
        "        # Start training\n",
        "        print(\"üî• Starting training...\")\n",
        "        results = model.train(**training_args)\n",
        "\n",
        "        print(\"‚úÖ Training completed successfully!\")\n",
        "\n",
        "        # Get training results\n",
        "        metrics = results.results_dict if hasattr(results, 'results_dict') else {}\n",
        "\n",
        "        print(f\"\\nüìä Training Results:\")\n",
        "        if metrics:\n",
        "            for key, value in metrics.items():\n",
        "                if isinstance(value, (int, float)):\n",
        "                    print(f\"   {key}: {value:.4f}\")\n",
        "\n",
        "        return model, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training failed: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Start training\n",
        "print(\"üöÄ Initiating maximum accuracy QR detection training...\")\n",
        "trained_model, training_results = train_maximum_accuracy_model()\n",
        "\n",
        "if trained_model is not None:\n",
        "    print(\"\\nüéâ Training pipeline completed successfully!\")\n",
        "    print(\"üìÅ Check 'qr_detection_max_accuracy' folder for results\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Training failed. Please check the error messages above.\")"
      ],
      "metadata": {
        "id": "xmKmqLzfly4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üñºÔ∏è Visualization & Testing\n",
        "def visualize_predictions(model_path, num_samples=6):\n",
        "    \"\"\"Visualize model predictions on sample images\"\"\"\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        print(f\"‚úÖ Loaded model from {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load model from {model_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"üñºÔ∏è Visualizing QR detection results...\")\n",
        "\n",
        "    # Get validation images\n",
        "    val_images = list((dataset_dir / \"val\" / \"images\").glob(\"*\"))\n",
        "    if not val_images:\n",
        "        print(\"‚ùå No validation images found\")\n",
        "        return\n",
        "\n",
        "    # Select random samples\n",
        "    sample_images = random.sample(val_images, min(num_samples, len(val_images)))\n",
        "\n",
        "    # Create visualization\n",
        "    cols = 3\n",
        "    rows = (len(sample_images) + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
        "    if rows == 1:\n",
        "        axes = [axes] if cols == 1 else axes\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for idx, img_path in enumerate(sample_images):\n",
        "        # Load and process image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Run prediction\n",
        "        results = model.predict(\n",
        "            str(img_path),\n",
        "            conf=CONFIDENCE_THRESHOLD,\n",
        "            iou=IOU_THRESHOLD,\n",
        "            imgsz=IMG_SIZE,\n",
        "            device=DEVICE,\n",
        "            verbose=False,\n",
        "            save=False\n",
        "        )\n",
        "\n",
        "        # Draw predictions\n",
        "        if len(results) > 0 and results[0].boxes is not None:\n",
        "            boxes = results[0].boxes\n",
        "            for i in range(len(boxes)):\n",
        "                # Get box coordinates\n",
        "                x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy().astype(int)\n",
        "                conf = boxes.conf[i].cpu().numpy()\n",
        "\n",
        "                # Draw bounding box\n",
        "                cv2.rectangle(image_rgb, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "                # Add confidence label\n",
        "                label = f'QR: {conf:.2f}'\n",
        "                cv2.putText(image_rgb, label, (x1, y1-10),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "        # Display image\n",
        "        if idx < len(axes):\n",
        "            axes[idx].imshow(image_rgb)\n",
        "            axes[idx].set_title(f\"Sample {idx+1}: {img_path.name}\")\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "    # Hide unused subplots\n",
        "    for idx in range(len(sample_images), len(axes)):\n",
        "        axes[idx].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('üéØ QR Detection Results', fontsize=16, fontweight='bold', y=0.98)\n",
        "    plt.show()\n",
        "\n",
        "def test_on_test_images(model_path):\n",
        "    \"\"\"Test model on test images\"\"\"\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "        print(f\"‚úÖ Loaded model from {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load model from {model_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"üß™ Testing on test images...\")\n",
        "\n",
        "    test_images = list(TEST_IMAGES.glob('*.jpg')) + list(TEST_IMAGES.glob('*.png'))\n",
        "    if not test_images:\n",
        "        print(\"‚ùå No test images found\")\n",
        "        return\n",
        "\n",
        "    total_detections = 0\n",
        "    images_with_qr = 0\n",
        "\n",
        "    print(f\"Testing on {len(test_images)} images...\")\n",
        "\n",
        "    for img_path in test_images[:10]:  # Test on first 10 images\n",
        "        results = model.predict(\n",
        "            str(img_path),\n",
        "            conf=CONFIDENCE_THRESHOLD,\n",
        "            iou=IOU_THRESHOLD,\n",
        "            imgsz=IMG_SIZE,\n",
        "            device=DEVICE,\n",
        "            verbose=False,\n",
        "            save=False\n",
        "        )\n",
        "\n",
        "        if len(results) > 0 and results[0].boxes is not None:\n",
        "            num_qr = len(results[0].boxes)\n",
        "            if num_qr > 0:\n",
        "                images_with_qr += 1\n",
        "                total_detections += num_qr\n",
        "                print(f\"   {img_path.name}: {num_qr} QR codes detected\")\n",
        "        else:\n",
        "            print(f\"   {img_path.name}: No QR codes detected\")\n",
        "\n",
        "    print(f\"\\nüìä Test Results:\")\n",
        "    print(f\"   Images with QR detected: {images_with_qr}/{min(10, len(test_images))}\")\n",
        "    print(f\"   Total QR codes detected: {total_detections}\")\n",
        "    print(f\"   Average QR per image: {total_detections/min(10, len(test_images)):.2f}\")\n",
        "\n",
        "# Run visualizations and testing\n",
        "# Use the path to the best weights from the training run\n",
        "best_model_path = \"/qr_detection_max_accuracy/qr_yolov8s_best_accuracy/weights/best.pt\"\n",
        "\n",
        "# Check if the trained_model variable exists and has the best weights path\n",
        "if 'trained_model' in globals() and trained_model is not None:\n",
        "    # Use the path from the training results if available\n",
        "    try:\n",
        "        best_model_path = str(Path(trained_model.save_dir) / \"weights\" / \"best.pt\")\n",
        "        print(f\"Using best model path from training results: {best_model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not get best model path from training results, using default: {best_model_path}\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "\n",
        "visualize_predictions(best_model_path)\n",
        "test_on_test_images(best_model_path)"
      ],
      "metadata": {
        "id": "Z_2fepMO1mkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üìà Training Curves & Performance Analysis\n",
        "def plot_training_curves(experiment_path):\n",
        "    \"\"\"Plot detailed training curves and metrics\"\"\"\n",
        "    if experiment_path is None:\n",
        "        print(\"‚ùå No experiment path available\")\n",
        "        return\n",
        "\n",
        "    print(\"üìà Plotting training curves...\")\n",
        "\n",
        "    results_file = experiment_path / \"results.csv\"\n",
        "    if not results_file.exists():\n",
        "        print(f\"‚ùå Results CSV not found at {results_file}\")\n",
        "        return\n",
        "\n",
        "    # Load training results\n",
        "    df = pd.read_csv(results_file)\n",
        "    df.columns = df.columns.str.strip()\n",
        "\n",
        "    # Create comprehensive plots\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(15, 18))\n",
        "    fig.suptitle('üéØ YOLOv8 QR Detection Training Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "    # Loss curves\n",
        "    axes[0, 0].plot(df.index, df['train/box_loss'], 'b-', label='Train Box Loss', linewidth=2)\n",
        "    axes[0, 0].plot(df.index, df['val/box_loss'], 'r-', label='Val Box Loss', linewidth=2)\n",
        "    axes[0, 0].set_title('Box Regression Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[0, 1].plot(df.index, df['train/cls_loss'], 'b-', label='Train Cls Loss', linewidth=2)\n",
        "    axes[0, 1].plot(df.index, df['val/cls_loss'], 'r-', label='Val Cls Loss', linewidth=2)\n",
        "    axes[0, 1].set_title('Classification Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # DFL Loss\n",
        "    if 'train/dfl_loss' in df.columns:\n",
        "        axes[1, 0].plot(df.index, df['train/dfl_loss'], 'b-', label='Train DFL Loss', linewidth=2)\n",
        "        axes[1, 0].plot(df.index, df['val/dfl_loss'], 'r-', label='Val DFL Loss', linewidth=2)\n",
        "        axes[1, 0].set_title('Distribution Focal Loss (DFL)')\n",
        "        axes[1, 0].set_xlabel('Epoch')\n",
        "        axes[1, 0].set_ylabel('Loss')\n",
        "        axes[1, 0].legend()\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Precision and Recall\n",
        "    if 'metrics/precision(B)' in df.columns:\n",
        "        axes[1, 1].plot(df.index, df['metrics/precision(B)'], 'g-', label='Precision', linewidth=2)\n",
        "        axes[1, 1].plot(df.index, df['metrics/recall(B)'], 'orange', label='Recall', linewidth=2)\n",
        "        axes[1, 1].set_title('Precision & Recall')\n",
        "        axes[1, 1].set_xlabel('Epoch')\n",
        "        axes[1, 1].set_ylabel('Value')\n",
        "        axes[1, 1].legend()\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "        axes[1, 1].set_ylim([0, 1])\n",
        "\n",
        "    # mAP metrics\n",
        "    if 'metrics/mAP50(B)' in df.columns:\n",
        "        axes[2, 0].plot(df.index, df['metrics/mAP50(B)'], 'purple', label='mAP@0.5', linewidth=2)\n",
        "        if 'metrics/mAP50-95(B)' in df.columns:\n",
        "            axes[2, 0].plot(df.index, df['metrics/mAP50-95(B)'], 'brown', label='mAP@0.5:0.95', linewidth=2)\n",
        "        axes[2, 0].set_title('Mean Average Precision (mAP)')\n",
        "        axes[2, 0].set_xlabel('Epoch')\n",
        "        axes[2, 0].set_ylabel('mAP')\n",
        "        axes[2, 0].legend()\n",
        "        axes[2, 0].grid(True, alpha=0.3)\n",
        "        axes[2, 0].set_ylim([0, 1])\n",
        "\n",
        "    # Learning rate\n",
        "    if 'lr/pg0' in df.columns:\n",
        "        axes[2, 1].plot(df.index, df['lr/pg0'], 'cyan', label='Learning Rate', linewidth=2)\n",
        "        axes[2, 1].set_title('Learning Rate Schedule')\n",
        "        axes[2, 1].set_xlabel('Epoch')\n",
        "        axes[2, 1].set_ylabel('Learning Rate')\n",
        "        axes[2, 1].legend()\n",
        "        axes[2, 1].grid(True, alpha=0.3)\n",
        "        axes[2, 1].set_yscale('log')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print final metrics summary\n",
        "    if len(df) > 0:\n",
        "        final_metrics = df.iloc[-1]\n",
        "        print(f\"\\nüìä Final Training Metrics:\")\n",
        "\n",
        "        metrics_to_show = [\n",
        "            ('metrics/precision(B)', 'Precision'),\n",
        "            ('metrics/recall(B)', 'Recall'),\n",
        "            ('metrics/mAP50(B)', 'mAP@0.5'),\n",
        "            ('metrics/mAP50-95(B)', 'mAP@0.5:0.95'),\n",
        "            ('val/box_loss', 'Validation Box Loss'),\n",
        "            ('val/cls_loss', 'Validation Cls Loss')\n",
        "        ]\n",
        "\n",
        "        for col, name in metrics_to_show:\n",
        "            if col in df.columns:\n",
        "                value = final_metrics[col]\n",
        "                print(f\"   {name}: {value:.4f}\")\n",
        "\n",
        "        # Best mAP50 epoch\n",
        "        if 'metrics/mAP50(B)' in df.columns:\n",
        "            best_map50_epoch = df['metrics/mAP50(B)'].idxmax()\n",
        "            best_map50_value = df['metrics/mAP50(B)'].max()\n",
        "            print(f\"\\nüèÜ Best Performance:\")\n",
        "            print(f\"   Best mAP@0.5: {best_map50_value:.4f} (Epoch {best_map50_epoch + 1})\")\n",
        "\n",
        "# Plot training analysis\n",
        "if 'training_results' in globals() and training_results is not None:\n",
        "    experiment_path = Path(training_results.save_dir)\n",
        "    plot_training_curves(experiment_path)\n",
        "else:\n",
        "    print(\"‚ùå Training results not available to plot curves.\")"
      ],
      "metadata": {
        "id": "97XhrWmLBG5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ Model Export & Production Deployment\n",
        "def export_production_models(model):\n",
        "    \"\"\"Export trained model in multiple formats for production deployment\"\"\"\n",
        "    if model is None:\n",
        "        print(\"‚ùå No model available for export\")\n",
        "        return\n",
        "\n",
        "    print(\"üöÄ Exporting model for production deployment...\")\n",
        "\n",
        "    export_results = {}\n",
        "    export_formats = ['onnx', 'torchscript', 'openvino']\n",
        "\n",
        "    for format_type in export_formats:\n",
        "        try:\n",
        "            print(f\"üì¶ Exporting to {format_type.upper()}...\")\n",
        "\n",
        "            if format_type == 'onnx':\n",
        "                # ONNX export for cross-platform deployment\n",
        "                export_path = model.export(\n",
        "                    format='onnx',\n",
        "                    imgsz=IMG_SIZE,\n",
        "                    half=False,  # FP32 for maximum compatibility\n",
        "                    int8=False,\n",
        "                    dynamic=True,  # Dynamic input shapes\n",
        "                    simplify=True,\n",
        "                    opset=17,  # Latest ONNX opset\n",
        "                    verbose=True\n",
        "                )\n",
        "\n",
        "            elif format_type == 'torchscript':\n",
        "                # TorchScript for PyTorch deployment\n",
        "                export_path = model.export(\n",
        "                    format='torchscript',\n",
        "                    imgsz=IMG_SIZE,\n",
        "                    optimize=True,\n",
        "                    half=False,\n",
        "                    verbose=True\n",
        "                )\n",
        "\n",
        "            elif format_type == 'openvino':\n",
        "                # OpenVINO for Intel hardware optimization\n",
        "                export_path = model.export(\n",
        "                    format='openvino',\n",
        "                    imgsz=IMG_SIZE,\n",
        "                    half=False,\n",
        "                    int8=False,\n",
        "                    verbose=True\n",
        "                )\n",
        "\n",
        "            export_results[format_type] = export_path\n",
        "            print(f\"   ‚úÖ {format_type.upper()} export successful: {export_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå {format_type.upper()} export failed: {str(e)}\")\n",
        "            export_results[format_type] = None\n",
        "\n",
        "    print(f\"\\nüì¶ Export Summary:\")\n",
        "    for format_type, path in export_results.items():\n",
        "        if path:\n",
        "            print(f\"   ‚úÖ {format_type.upper()}: {path}\")\n",
        "        else:\n",
        "            print(f\"   ‚ùå {format_type.upper()}: Export failed\")\n",
        "\n",
        "    return export_results\n",
        "\n",
        "def create_inference_function(model):\n",
        "    \"\"\"Create a production-ready inference function\"\"\"\n",
        "    if model is None:\n",
        "        print(\"‚ùå No model available\")\n",
        "        return None\n",
        "\n",
        "    def detect_qr_codes(image_path, conf_threshold=0.25, iou_threshold=0.5):\n",
        "        \"\"\"\n",
        "        Detect QR codes in an image\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to the image file\n",
        "            conf_threshold: Confidence threshold for detection\n",
        "            iou_threshold: IoU threshold for NMS\n",
        "\n",
        "        Returns:\n",
        "            List of detections with bounding boxes and confidence scores\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Run prediction\n",
        "            results = model.predict(\n",
        "                source=image_path,\n",
        "                conf=conf_threshold,\n",
        "                iou=iou_threshold,\n",
        "                imgsz=IMG_SIZE,\n",
        "                device=DEVICE,\n",
        "                verbose=False,\n",
        "                save=False\n",
        "            )\n",
        "\n",
        "            detections = []\n",
        "            if len(results) > 0 and results[0].boxes is not None:\n",
        "                boxes = results[0].boxes\n",
        "\n",
        "                for i in range(len(boxes)):\n",
        "                    # Get detection data\n",
        "                    bbox = boxes.xyxy[i].cpu().numpy()  # [x1, y1, x2, y2]\n",
        "                    conf = boxes.conf[i].cpu().numpy()\n",
        "\n",
        "                    detection = {\n",
        "                        'bbox': bbox.tolist(),\n",
        "                        'confidence': float(conf),\n",
        "                        'class': 'QR_Code',\n",
        "                        'x1': float(bbox[0]),\n",
        "                        'y1': float(bbox[1]),\n",
        "                        'x2': float(bbox[2]),\n",
        "                        'y2': float(bbox[3]),\n",
        "                        'width': float(bbox[2] - bbox[0]),\n",
        "                        'height': float(bbox[3] - bbox[1])\n",
        "                    }\n",
        "                    detections.append(detection)\n",
        "\n",
        "            return detections\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during inference: {e}\")\n",
        "            return []\n",
        "\n",
        "    return detect_qr_codes\n",
        "\n",
        "def save_model_info(experiment_path):\n",
        "    \"\"\"Save model configuration and performance info\"\"\"\n",
        "    if experiment_path is None:\n",
        "        return\n",
        "\n",
        "    model_info = {\n",
        "        'model_type': SELECTED_MODEL,\n",
        "        'training_config': {\n",
        "            'epochs': EPOCHS,\n",
        "            'batch_size': BATCH_SIZE,\n",
        "            'image_size': IMG_SIZE,\n",
        "            'learning_rate': LEARNING_RATE,\n",
        "            'device': DEVICE\n",
        "        },\n",
        "        'dataset_info': dataset_stats,\n",
        "        'paths': {\n",
        "            'train_images': str(TRAIN_IMAGES),\n",
        "            'train_labels': str(TRAIN_LABELS),\n",
        "            'test_images': str(TEST_IMAGES),\n",
        "            'test_labels': str(TEST_LABELS)\n",
        "        },\n",
        "        'usage_instructions': {\n",
        "            'inference': 'Use detect_qr_codes(image_path) function',\n",
        "            'confidence_threshold': CONFIDENCE_THRESHOLD,\n",
        "            'iou_threshold': IOU_THRESHOLD,\n",
        "            'supported_formats': ['jpg', 'png', 'jpeg'],\n",
        "            'output_format': 'List of detections with bbox coordinates and confidence'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    info_file = experiment_path / 'model_info.json'\n",
        "    with open(info_file, 'w') as f:\n",
        "        json.dump(model_info, f, indent=2)\n",
        "\n",
        "    print(f\"üìÑ Model info saved: {info_file}\")\n",
        "\n",
        "\n",
        "# Export models and create inference function\n",
        "if 'trained_model' in globals() and trained_model is not None:\n",
        "    # Export to different formats\n",
        "    export_results = export_production_models(trained_model)\n",
        "\n",
        "    # Create inference function\n",
        "    qr_detector = create_inference_function(trained_model)\n",
        "\n",
        "    # Save model information\n",
        "    if 'training_results' in globals() and training_results is not None:\n",
        "        experiment_path = Path(training_results.save_dir)\n",
        "        save_model_info(experiment_path)\n",
        "    else:\n",
        "        print(\"‚ùå Training results not available to save model info.\")\n",
        "\n",
        "\n",
        "    print(f\"\\nüéâ Production deployment ready!\")\n",
        "    print(f\"üìÅ Model files: qr_detection_max_accuracy/\")\n",
        "    print(f\"üîß Use 'qr_detector(image_path)' function for inference\")\n",
        "\n",
        "    # Test the inference function on a sample image\n",
        "    if qr_detector is not None:\n",
        "        test_images = list(TEST_IMAGES.glob('*.jpg'))[:1]\n",
        "        if test_images:\n",
        "            print(f\"\\nüß™ Testing inference function...\")\n",
        "            sample_img = test_images[0]\n",
        "            detections = qr_detector(str(sample_img))\n",
        "            print(f\"   Sample detection on {sample_img.name}: {len(detections)} QR codes found\")\n",
        "            for i, det in enumerate(detections):\n",
        "                print(f\"     QR {i+1}: Confidence {det['confidence']:.3f}, Box: ({det['x1']:.0f}, {det['y1']:.0f}, {det['x2']:.0f}, {det['y2']:.0f})\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No trained model available for export\")"
      ],
      "metadata": {
        "id": "l6_BzjkNBLTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9kpjXXhBLFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb3a4e40"
      },
      "source": [
        "# Task\n",
        "Debug and resolve the CUDA errors encountered during YOLOv8 training, then resume or restart training to achieve the desired accuracy, potentially increasing the number of epochs if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35b31f90"
      },
      "source": [
        "## Address cuda error\n",
        "\n",
        "### Subtask:\n",
        "Implement strategies to resolve the \"CUDA error: resource already mapped\", such as checking for conflicting processes, trying different CUDA versions if possible, or adding specific PyTorch environment variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac1da862"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement strategies to resolve the CUDA error by checking for conflicting processes and setting the `PYTORCH_CUDA_ALLOC_CONF` environment variable before attempting to train the model again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e08e919"
      },
      "source": [
        "# üîß Debugging CUDA Errors\n",
        "\n",
        "print(\"üîç Attempting to resolve CUDA errors...\")\n",
        "\n",
        "# Step 1: Check for conflicting processes (Manual Step - Instruct the user)\n",
        "print(\"\\nStep 1: Check for conflicting processes.\")\n",
        "print(\"Please manually check for any other applications or processes that might be using your GPU (e.g., other training sessions, games, video editing software).\")\n",
        "print(\"If you find any, close them and try re-running the training cell.\")\n",
        "print(\"On Windows, you can use Task Manager (Performance tab, GPU section).\")\n",
        "print(\"On Linux, you can use `nvidia-smi` in the terminal.\")\n",
        "\n",
        "\n",
        "# Step 2: Set PYTORCH_CUDA_ALLOC_CONF environment variable\n",
        "print(\"\\nStep 2: Setting PYTORCH_CUDA_ALLOC_CONF environment variable.\")\n",
        "try:\n",
        "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'\n",
        "    print(\"‚úÖ PYTORCH_CUDA_ALLOC_CONF set to 'max_split_size_mb:512'\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Failed to set PYTORCH_CUDA_ALLOC_CONF: {e}\")\n",
        "\n",
        "# Step 3 & 4: CUDA version switching, Driver/Hardware issues (Manual Steps - Instruct the user)\n",
        "print(\"\\nStep 3 & 4: CUDA Version / Driver / Hardware Check.\")\n",
        "print(\"If the error persists after closing conflicting processes and setting PYTORCH_CUDA_ALLOC_CONF, consider:\")\n",
        "print(\"  - Ensuring your NVIDIA drivers are up to date and compatible with your PyTorch and CUDA versions.\")\n",
        "print(\"  - If you have multiple CUDA versions installed, try switching to a different one compatible with your PyTorch installation.\")\n",
        "print(\"These steps are manual and depend on your system configuration.\")\n",
        "\n",
        "print(\"\\nAttempting to re-run the training cell after applying potential fixes...\")\n",
        "\n",
        "# Re-run the training function\n",
        "# Note: The training function `train_maximum_accuracy_model` is defined in cell xmKmqLzfly4Q.\n",
        "# We call it again here to attempt training with the new environment variable setting.\n",
        "print(\"\\nüöÄ Re-running maximum accuracy QR detection training...\")\n",
        "trained_model, training_results = train_maximum_accuracy_model()\n",
        "\n",
        "if trained_model is not None:\n",
        "    print(\"\\nüéâ Training pipeline completed successfully after attempting fixes!\")\n",
        "    print(\"üìÅ Check 'qr_detection_max_accuracy' folder for results\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Training failed again. Review the output above for new error messages.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}